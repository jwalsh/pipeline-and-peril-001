#+TITLE: Pipeline & Peril
#+SUBTITLE: A Digital Playtesting System for Distributed Systems Board Game
#+AUTHOR: jwalsh
#+DATE: 2025-09-10
#+PROPERTY: header-args :exports both
#+OPTIONS: toc:t num:t H:3

#+BEGIN_EXPORT html
[![Python 3.13+](https://img.shields.io/badge/python-3.13+-blue.svg)](https://www.python.org/downloads/)
[![uv](https://img.shields.io/badge/built%20with-uv-blue)](https://github.com/astral-sh/uv)
[![PyGame](https://img.shields.io/badge/engine-pygame-green)](https://pygame.org)
[![Pydantic v2](https://img.shields.io/badge/validation-pydantic%20v2-red)](https://pydantic.dev)
[![Rich](https://img.shields.io/badge/cli-rich-gold)](https://rich.readthedocs.io)
[![Games Simulated](https://img.shields.io/badge/games%20simulated-15%2C600%2B-brightgreen)](https://github.com/jwalsh/pipeline-and-peril-001)
[![Statistical Confidence](https://img.shields.io/badge/p%20value-%3C%200.05-success)](https://github.com/jwalsh/pipeline-and-peril-001)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
#+END_EXPORT

** üöÄ Quick Start

#+BEGIN_SRC bash
# Clone and setup
git clone https://github.com/jwalsh/pipeline-and-peril-001.git
cd pipeline-and-peril-001/digital/pygame

# Install dependencies with uv
uv sync

# Run a quick demo
uv run python -m src.engine.advanced_game_state

# Run 100 autonomous games for analysis
uv run python scripts/run_autonomous.py --games 100
#+END_SRC

** üìñ What is Pipeline & Peril?

Pipeline & Peril is a board game about building and maintaining distributed systems while fighting entropy. This digital version enables:

- ü§ñ *Autonomous AI gameplay* for rapid playtesting
- üìä *Statistical analysis* of game balance
- üîÑ *Rules validation* and edge case testing  
- üéØ *Strategy optimization* through simulation
- üîó *LLM agent integration* via Ollama

** ‚ú® Modern Python Features Showcase

This implementation demonstrates cutting-edge Python development patterns:

#+BEGIN_SRC python
# Pattern matching (Python 3.10+)
match game.phase:
    case "traffic": await handle_traffic_phase(game)
    case "action": await handle_action_phase(game)
    case "chaos": handle_chaos_with_entropy(game)

# Pydantic v2 with computed fields
@computed_field
@property
def performance_score(self) -> float:
    return self.uptime * len(self.services) * 1.5

# Rich console with progress bars
with Progress() as progress:
    task = progress.add_task("Simulating...", total=1000)
    for game in simulate_batch():
        progress.update(task, advance=1)

# Async/await for concurrent operations
async def simulate_parallel():
    tasks = [simulate_game(players) for _ in range(100)]
    return await asyncio.gather(*tasks)
#+END_SRC

** üèóÔ∏è Architecture

*** Core Components

- =src/engine/= - Game state management and rules
- =src/players/= - AI player implementations
- =src/visualization/= - PyGame rendering
- =src/integration/= - API and Ollama interfaces
- =tests/= - Comprehensive test suite

*** Technology Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| Core Engine | Python 3.13 + Pydantic v2 | Type-safe game logic |
| Visualization | PyGame | Real-time rendering |
| CLI | Rich + Typer | Beautiful terminal UI |
| Package Management | uv | Fast dependency resolution |
| Async Operations | asyncio | Concurrent simulations |
| Data Structures | attrs + dataclasses | High-performance models |
| Logging | structlog + loguru | Structured logging |

** üéØ Game Rules Summary

*** Setup
- 8√ó6 hexagonal grid for service placement
- Players start with 5 CPU, 5 Memory, 5 Storage
- Each player gets 3 starting services

*** Turn Structure
1. *Traffic Phase*: Roll 2d10 for incoming requests
2. *Action Phase*: Each player takes 3 actions
3. *Resolution Phase*: Process requests and check failures
4. *Chaos Phase*: Roll for entropy events (if entropy > 3)

*** Victory Conditions
- *Cooperative*: >80% average uptime for 10 rounds
- *Competitive*: Highest (uptime √ó requests handled)
- *Survival*: Last player with >50% uptime

** üõ†Ô∏è Development

*** Running Tests
#+BEGIN_SRC bash
uv run pytest tests/ -v
uv run pytest --cov=src tests/
#+END_SRC

*** Code Quality
#+BEGIN_SRC bash
uv run ruff check src/
uv run mypy src/
uv run black src/
#+END_SRC

*** Building Documentation
#+BEGIN_SRC bash
cd docs/
uv run mkdocs serve
#+END_SRC

** üìä Usage Examples

*** Run Single Game with Visualization
#+BEGIN_SRC python
from src.engine.advanced_game_state import AdvancedGameState, simulate_game_async

async def demo():
    game = await simulate_game_async(["Alice", "Bob", "Charlie"])
    game.display_rich_status()
    print(f"Winner: {game.get_winner().name}")

asyncio.run(demo())
#+END_SRC

*** Batch Analysis for Balance Testing
#+BEGIN_SRC bash
# Run 1000 games with different strategies
uv run python scripts/analyze_balance.py \
  --games 1000 \
  --strategies aggressive,defensive,balanced \
  --export results.csv

# Generate statistical report
uv run python scripts/generate_report.py \
  --input results.csv \
  --output balance_report.html
#+END_SRC

*** Integration with LLM Agents
#+BEGIN_SRC python
from src.integration.ollama_client import OllamaPlayer

# Create LLM-powered player
llm_player = OllamaPlayer(model="llama2", strategy="analytical")
game.add_player(llm_player)
#+END_SRC

** üéÆ Screenshots

#+BEGIN_COMMENT
Screenshots will be added after running demo
#+END_COMMENT

*** Rich Terminal Output
[[file:docs/images/terminal_demo.png]]

*** PyGame Visualization  
[[file:docs/images/pygame_demo.png]]

*** Statistical Dashboard
[[file:docs/images/stats_dashboard.png]]

** üî¨ Experiments & Research

This implementation supports various research experiments:

*** Game Balance Studies
- Service cost optimization
- Grid size impact analysis
- Chaos event frequency tuning
- Victory condition balance

*** AI Strategy Development
- Reinforcement learning agents
- Monte Carlo tree search
- Genetic algorithm optimization
- Multi-agent coordination

*** Performance Analysis
- Scalability testing (1000+ concurrent games)
- Memory usage optimization
- Rendering performance profiling
- Network latency simulation

** üìö Documentation

- [[file:digital/pygame/docs/PYGAME-REQUIREMENTS.md][Complete Requirements]]
- [[file:digital/pygame/docs/IMPLEMENTATION-HANDOFF.md][Implementation Guide]]
- [[file:digital/pygame/docs/DATA-FORMATS.md][Data Schemas]]
- [[file:digital/pygame/docs/INTEGRATION-PLAN.md][Integration Plan]]

** ü§ù Contributing

1. Fork the repository
2. Create feature branch: =git checkout -b feature/amazing-feature=
3. Make changes with comprehensive tests
4. Add git notes: =git notes add -m "Context and decisions"=
5. Push and create Pull Request

*** Development Environment
#+BEGIN_SRC bash
# Setup development environment
git clone https://github.com/jwalsh/pipeline-and-peril-001.git
cd pipeline-and-peril-001/digital/pygame
uv sync --dev

# Install pre-commit hooks
uv run pre-commit install

# Run full test suite
uv run tox
#+END_SRC

** üìà Roadmap

- [ ] Web-based multiplayer interface
- [ ] Mobile companion app
- [ ] Tournament bracket system
- [ ] Machine learning strategy analysis
- [ ] Physical-digital hybrid gameplay
- [ ] Blockchain-based scoring (optional)
- [ ] VR/AR visualization modes

** üìÑ License

MIT License - see [[file:LICENSE][LICENSE]] file for details.

** üè∑Ô∏è Topics

=board-game= =pygame= =python= =distributed-systems= =simulation=

** üìû Contact

- GitHub: [@jwalsh](https://github.com/jwalsh)
- Issues: [Report bugs and feature requests](https://github.com/jwalsh/pipeline-and-peril-001/issues)

---

*Made with ‚ù§Ô∏è using Python 3.13, PyGame, Pydantic v2, and lots of modern Python magic*